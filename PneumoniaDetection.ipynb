{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Junction/Pneumonia-Detection/blob/master/PneumoniaDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0NoF022TreRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check memory allocation to this sesssion"
      ]
    },
    {
      "metadata": {
        "id": "HiC2mY5E57ad",
        "colab_type": "code",
        "outputId": "3d3a3c50-649e-47dc-90f7-f6c7d932a6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G   18G  323G   6% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G  8.0K  6.4G   1% /var/colab\n",
            "/dev/sda1       365G   22G  344G   6% /opt/bin\n",
            "shm             6.0G     0  6.0G   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTGfs5-Q27X_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "id": "BN9O5cVk2uJH",
        "colab_type": "code",
        "outputId": "08f60bc0-c215-4222-d46b-645561773940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o40Dy-h431QS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check RAM allocation in current session"
      ]
    },
    {
      "metadata": {
        "id": "dm9C91QJ30RX",
        "colab_type": "code",
        "outputId": "f707e286-3046-430e-ad00-c472b3ad206d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.5 GB  | Proc size: 692.6 MB\n",
            "GPU RAM Free: 11325MB | Used: 116MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-PFAjmv2yzZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "**** Uncomment below cell if needed"
      ]
    },
    {
      "metadata": {
        "id": "bzbVk-cP2x9c",
        "colab_type": "code",
        "outputId": "ad3d9bbb-866d-4978-c9b6-d5f519f8c77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nimport tensorflow as tf\\nimport timeit\\n\\n# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\\nconfig = tf.ConfigProto()\\nconfig.gpu_options.allow_growth = True\\n\\nwith tf.device(\\'/cpu:0\\'):\\n  random_image_cpu = tf.random_normal((100, 100, 100, 3))\\n  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\\n  net_cpu = tf.reduce_sum(net_cpu)\\n\\nwith tf.device(\\'/gpu:0\\'):\\n  random_image_gpu = tf.random_normal((100, 100, 100, 3))\\n  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\\n  net_gpu = tf.reduce_sum(net_gpu)\\n\\nsess = tf.Session(config=config)\\n\\n# Test execution once to detect errors early.\\ntry:\\n  sess.run(tf.global_variables_initializer())\\nexcept tf.errors.InvalidArgumentError:\\n  print(\\n      \\'\\n\\nThis error most likely means that this notebook is not \\'\\n      \\'configured to use a GPU.  Change this in Notebook Settings via the \\'\\n      \\'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n\\')\\n  raise\\n\\ndef cpu():\\n  sess.run(net_cpu)\\n  \\ndef gpu():\\n  sess.run(net_gpu)\\n  \\n# Runs the op several times.\\nprint(\\'Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images \\'\\n      \\'(batch x height x width x channel). Sum of ten runs.\\')\\nprint(\\'CPU (s):\\')\\ncpu_time = timeit.timeit(\\'cpu()\\', number=10, setup=\"from __main__ import cpu\")\\nprint(cpu_time)\\nprint(\\'GPU (s):\\')\\ngpu_time = timeit.timeit(\\'gpu()\\', number=10, setup=\"from __main__ import gpu\")\\nprint(gpu_time)\\nprint(\\'GPU speedup over CPU: {}x\\'.format(int(cpu_time/gpu_time)))\\n\\nsess.close()\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JQ5kplL6sbfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check total memory allocation\n",
        "\n",
        "*** Uncomment below cell only if needed"
      ]
    },
    {
      "metadata": {
        "id": "kcFqYxzH9z7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWOpFaOIsl6T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check versions of various libraries installed in this session of colaboratory\n",
        "\n",
        "**** Uncomment below cell only if needed"
      ]
    },
    {
      "metadata": {
        "id": "HbIRMWHURzeQ",
        "colab_type": "code",
        "outputId": "2e46703e-5cff-45cf-8ef1-4e53870c2fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
        "print(\"Python version: {}\". format(sys.version))\n",
        "\n",
        "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
        "print(\"pandas version: {}\". format(pd.__version__))\n",
        "\n",
        "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
        "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
        "\n",
        "import numpy as np #foundational package for scientific computing\n",
        "print(\"NumPy version: {}\". format(np.__version__))\n",
        "\n",
        "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
        "print(\"SciPy version: {}\". format(sp.__version__)) \n",
        "\n",
        "import IPython\n",
        "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
        "print(\"IPython version: {}\". format(IPython.__version__)) \n",
        "\n",
        "import sklearn #collection of machine learning algorithms\n",
        "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
        "\n",
        "#misc libraries\n",
        "import random\n",
        "import time\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\\nprint(\"Python version: {}\". format(sys.version))\\n\\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\\nprint(\"pandas version: {}\". format(pd.__version__))\\n\\nimport matplotlib #collection of functions for scientific and publication-ready visualization\\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\\n\\nimport numpy as np #foundational package for scientific computing\\nprint(\"NumPy version: {}\". format(np.__version__))\\n\\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\\nprint(\"SciPy version: {}\". format(sp.__version__)) \\n\\nimport IPython\\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\\nprint(\"IPython version: {}\". format(IPython.__version__)) \\n\\nimport sklearn #collection of machine learning algorithms\\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\\n\\n#misc libraries\\nimport random\\nimport time\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Kw8e1sxsWAYO",
        "colab_type": "code",
        "outputId": "a9f8c3f6-d165-4e21-e1ca-48bde12b71d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "!git clone https://gist.github.com/dc7e60aa487430ea704a8cb3f2c5d6a6.git /tmp/colab_util_repo\n",
        "!mv /tmp/colab_util_repo/colab_util.py colab_util.py \n",
        "!rm -r /tmp/colab_util_repo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/colab_util_repo'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "Unpacking objects:   2% (1/40)   \rUnpacking objects:   5% (2/40)   \rUnpacking objects:   7% (3/40)   \rUnpacking objects:  10% (4/40)   \rUnpacking objects:  12% (5/40)   \rUnpacking objects:  15% (6/40)   \rUnpacking objects:  17% (7/40)   \rUnpacking objects:  20% (8/40)   \rUnpacking objects:  22% (9/40)   \rUnpacking objects:  25% (10/40)   \rUnpacking objects:  27% (11/40)   \rUnpacking objects:  30% (12/40)   \rUnpacking objects:  32% (13/40)   \rUnpacking objects:  35% (14/40)   \rUnpacking objects:  37% (15/40)   \rUnpacking objects:  40% (16/40)   \rUnpacking objects:  42% (17/40)   \rUnpacking objects:  45% (18/40)   \rUnpacking objects:  47% (19/40)   \rUnpacking objects:  50% (20/40)   \rUnpacking objects:  52% (21/40)   \rUnpacking objects:  55% (22/40)   \rUnpacking objects:  57% (23/40)   \rUnpacking objects:  60% (24/40)   \rUnpacking objects:  62% (25/40)   \rUnpacking objects:  65% (26/40)   \rUnpacking objects:  67% (27/40)   \rUnpacking objects:  70% (28/40)   \rUnpacking objects:  72% (29/40)   \rUnpacking objects:  75% (30/40)   \rUnpacking objects:  77% (31/40)   \rUnpacking objects:  80% (32/40)   \rUnpacking objects:  82% (33/40)   \rUnpacking objects:  85% (34/40)   \rUnpacking objects:  87% (35/40)   \rUnpacking objects:  90% (36/40)   \rUnpacking objects:  92% (37/40)   \rUnpacking objects:  95% (38/40)   \rUnpacking objects:  97% (39/40)   \rUnpacking objects: 100% (40/40)   \rUnpacking objects: 100% (40/40), done.\n",
            "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjBOuMRy3gnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!ls -l /tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7hM__AsVyTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from colab_util import *\n",
        "drive_handler = GoogleDriveHandler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUz-iLKIitkt",
        "colab_type": "code",
        "outputId": "cfc665ec-a57a-4483-b1bc-8b2ffc00a629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4JRbSL-ToWIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "De3f_YB8obZP",
        "colab_type": "code",
        "outputId": "e9f11161-814b-438d-f1c8-7d1a1a88fe5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "#filename = \"/content/.kaggle/kaggle.json\"\n",
        "#filename = \"/.kaggle/kaggle.json\"\n",
        "filename = \"kaggle.json\"\n",
        "#os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QJZsCT4o3A5",
        "colab_type": "code",
        "outputId": "6980407c-ed3a-4b3e-faf6-c8023888f028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---x-wx--T 1 root root 65 Dec 23 16:36 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxb8N3E3o8FN",
        "colab_type": "code",
        "outputId": "9ade2d0a-8261-427f-d2b6-200a7950bfcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"/root/.kaggle\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "9uUUcDqhpAuJ",
        "colab_type": "code",
        "outputId": "f47d8c41-3e0b-4042-b8cb-f96dc1502f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dir_kaggle = \"/root/.kaggle\"\n",
        "if not os.path.isdir(dir_kaggle):\n",
        "  !mkdir -p ~/.kaggle  \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "os.path.isdir(dir_kaggle)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "_ErgTi5tpFFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IS_LrIG9B-v5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create training and test data in this allocated session of colaboratory"
      ]
    },
    {
      "metadata": {
        "id": "eBXyjtrhB-QX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/Histopathologic-Cancer-Detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rk6WHL0CGfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/test'):\n",
        "  !mkdir '/content/Histopathologic-Cancer-Detection/test'\n",
        "  \n",
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/train'):\n",
        "  !mkdir '/content/Histopathologic-Cancer-Detection/train'  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYh3dkXAFRzA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To copy file into colab from GCD"
      ]
    },
    {
      "metadata": {
        "id": "6UZhjDONCOWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('/content/Histopathologic-Cancer-Detection/test.zip'):\n",
        "  !cp '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test.zip' '/content/Histopathologic-Cancer-Detection'\n",
        "else:\n",
        "  print('file exists')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkNdgVAFCxwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "HCDBaseDirTestDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/test/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTestDir_files]\n",
        "print(len(archived_files))\n",
        "if len(archived_files) == 0:\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/test.zip\" -d \"/content/Histopathologic-Cancer-Detection/test/\"\n",
        "  print(len(archived_files) + ' files unzipped')\n",
        "else:\n",
        "  print('already unzipped')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYbFQ5wz8O4H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HCDBaseDirTestDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/test/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTestDir_files]\n",
        "print(len(archived_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlccqHaQpZJS",
        "colab_type": "code",
        "outputId": "6e214183-9ce5-4693-f2d5-2fa6a5400c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions files -c histopathologic-cancer-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name                   size  creationDate         \n",
            "---------------------  ----  -------------------  \n",
            "sample_submission.csv   2MB  2018-11-15 23:20:36  \n",
            "train_labels.csv        9MB  2018-11-15 23:20:37  \n",
            "test.zip                1GB  2018-11-15 23:21:06  \n",
            "train.zip               5GB  2018-11-15 23:23:49  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eDE--qt0FLUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/model.h5' '/content/Histopathologic-Cancer-Detection/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i17v-gxzOiFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download competition files to colab folders"
      ]
    },
    {
      "metadata": {
        "id": "VofS_vnzs5ZU",
        "colab_type": "code",
        "outputId": "8650bf75-939f-4120-b945-95312d5e0a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/train_labels.csv.zip\"):\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f sample_submission.csv -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f train_labels.csv -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f test.zip -p \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  !kaggle competitions download -c histopathologic-cancer-detection -f train.zip -p \"/content/Histopathologic-Cancer-Detection/\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv.zip to /content/Histopathologic-Cancer-Detection\n",
            "\r  0% 0.00/1.33M [00:00<?, ?B/s]\n",
            "100% 1.33M/1.33M [00:00<00:00, 44.2MB/s]\n",
            "Downloading train_labels.csv.zip to /content/Histopathologic-Cancer-Detection\n",
            "  0% 0.00/5.10M [00:00<?, ?B/s]\n",
            "100% 5.10M/5.10M [00:00<00:00, 46.9MB/s]\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading train.zip to /content/Histopathologic-Cancer-Detection\n",
            "100% 4.97G/4.98G [00:37<00:00, 134MB/s]\n",
            "100% 4.98G/4.98G [00:37<00:00, 142MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kbl9P1_EP4E1",
        "colab_type": "code",
        "outputId": "902eade6-deae-4060-a2d2-f11ff5f6dacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/train_labels.csv\"):\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/train_labels.csv.zip\" -d \"/content/Histopathologic-Cancer-Detection/\"\n",
        "  \n",
        "if not os.path.isfile(\"/content/Histopathologic-Cancer-Detection/sample_submission.csv\"):\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/sample_submission.csv.zip\" -d \"/content/Histopathologic-Cancer-Detection/\"  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Histopathologic-Cancer-Detection/train_labels.csv.zip\n",
            "  inflating: /content/Histopathologic-Cancer-Detection/train_labels.csv  \n",
            "Archive:  /content/Histopathologic-Cancer-Detection/sample_submission.csv.zip\n",
            "  inflating: /content/Histopathologic-Cancer-Detection/sample_submission.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C5-bdIevPrSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HCDTrainDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/train/*'))\n",
        "archived_files = 0\n",
        "archived_files = [f for f in HCDTrainDir_files]\n",
        "print(len(archived_files))\n",
        "if len(archived_files) == 0:\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/train.zip\" -d \"/content/Histopathologic-Cancer-Detection/train/\"\n",
        "else:\n",
        "  print('already unzipped')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XaIGdZrxQcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv\"):\n",
        "  !unzip \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/train_labels.csv.zip\" -d \"drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGaa5VPSlzmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UyhP6hulGkQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GoogleDriveHandler?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_fGiy0QHFQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gcd_ID = drive_handler.path_to_id('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/')\n",
        "gcd_ID\n",
        "#drive_handler.list_folder(gcd_ID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2Nwr2htcioi",
        "colab_type": "code",
        "outputId": "1ce79d23-7015-49bf-c026-9169ccb88f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.path.isdir('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir/train_dir/a_no_tumor_tissue/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jQK6aofxs3q4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#import glob\n",
        "HCDBaseDirTrainDir_files = sorted(glob.glob('/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir/train_dir/a_no_tumor_tissue/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTrainDir_files]\n",
        "print(len(archived_files))\n",
        "\n",
        "\n",
        "#for f in archived_files:\n",
        "#    print(f)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "erjV7py5szmR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cp -r '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/base_dir' '/content/Histopathologic-Cancer-Detection/base_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IzaBFz80LBBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#tar_file_path = create_archive('HCDBaseDirTrainDir', local_file_paths=archived_files[:10], verbose=True)\n",
        "#tar_file_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZFSmB4BGtU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print([x for x in dir(GoogleDriveHandler)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eb1RH2COtRTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example of how to archive files in notebook"
      ]
    },
    {
      "metadata": {
        "id": "FaFEMFw2Y4mR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "ipynb_files = sorted(glob.glob('sample_data/*.csv'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in ipynb_files]\n",
        "for f in archived_files:\n",
        "    print(f)\n",
        "    \n",
        "'''    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcddNqKVZfuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tar_file_path = create_archive('sample_archive', local_file_paths=archived_files, verbose=True)\n",
        "#tar_file_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mNY-dRYAaMvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!ls -l '/tmp/sample_archive.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1njth6sWtuYd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example of how to create folders in GCD using drive handler"
      ]
    },
    {
      "metadata": {
        "id": "NbtRPdTJWSlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "test_folder_id = drive_handler.create_folder('test_folder')\n",
        "test_folder_id\n",
        "\n",
        "test_subfolder_id = drive_handler.create_folder('test_sub_folder', parent_path='test_folder')\n",
        "test_subfolder_id\n",
        "\n",
        "same_subfolder_id = drive_handler.create_folder('test_sub_folder', parent_path='test_folder')\n",
        "test_subfolder_id\n",
        "\n",
        "same_subfolder_id2 = drive_handler.create_folder('test_sub_folder2', parent_path='test_folder')\n",
        "test_subsubfolder_id = drive_handler.create_folder('test_sub_sub_folder', parent_path='test_folder/test_sub_folder2')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAneW8j3uNMO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Examples of how to access list of files in a folder using drive handler"
      ]
    },
    {
      "metadata": {
        "id": "3quUhR4HW_fh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "ID = drive_handler.path_to_id('test_folder/test_sub_folder2/test_sub_sub_folder')\n",
        "ID, test_subsubfolder_id\n",
        "\n",
        "drive_handler.list_folder(test_folder_id)\n",
        "drive_handler.list_folder(test_folder_id, max_depth=1)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caem35IcuxuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To upload file to GCD"
      ]
    },
    {
      "metadata": {
        "id": "lWsdFCaOXEO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#drive_handler.upload(tar_file_path, parent_path='test_folder/test_sub_folder2')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZ1v1vJ_u6Ob",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To download file into Colab from GCD"
      ]
    },
    {
      "metadata": {
        "id": "PAsayaIzbc_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#drive_handler.download('/tmp/downloaded_archive.tar.gz', target_path='test_folder/test_sub_folder2/sample_archive.tar.gz')\n",
        "#!ls -l '/tmp/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwrXvcWV9OA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "ipynb_files = sorted(glob.glob('sample_data/*.csv'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in ipynb_files]\n",
        "for f in archived_files:\n",
        "    print(f)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7dgMvZ_Tguw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mcs11Y2hj2ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(101)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgoq9Msnj7RU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 96\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "SAMPLE_SIZE = 80000 # the number of images we use from each of the two classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XbwOmE6xIMh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Give read write access to train_labels.csv"
      ]
    },
    {
      "metadata": {
        "id": "eRxl9YPqw1EV",
        "colab_type": "code",
        "outputId": "4c6257e9-93af-4ad8-d212-12b63e767fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l '/content/Histopathologic-Cancer-Detection/train_labels.csv'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- 1 root root 9461084 Nov 15 23:48 /content/Histopathologic-Cancer-Detection/train_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-9uxNwsTmec9",
        "colab_type": "code",
        "outputId": "d58cb031-9a3d-4ec1-d036-e50f030c51f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 '/content/Histopathologic-Cancer-Detection/train_labels.csv'\n",
        "!ls -l '/content/Histopathologic-Cancer-Detection/train_labels.csv'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 9461084 Nov 15 23:48 /content/Histopathologic-Cancer-Detection/train_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jdJrIJy9kWRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv('/content/Histopathologic-Cancer-Detection/train_labels.csv', engine='python')\n",
        "\n",
        "# removing this image because it caused a training error previously\n",
        "df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
        "\n",
        "# removing this image because it's black\n",
        "df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
        "\n",
        "\n",
        "print(df_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbJNi6N5nDNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uyCG8j1n-a4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# source: https://www.kaggle.com/gpreda/honey-bee-subspecies-classification\n",
        "\n",
        "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
        "    \n",
        "    \"\"\"\n",
        "    Give a column in a dataframe,\n",
        "    this function takes a sample of each class and displays that\n",
        "    sample on one row. The sample size is the same as figure_cols which\n",
        "    is the number of columns in the figure.\n",
        "    Because this function takes a random sample, each time the function is run it\n",
        "    displays different images.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
        "    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n",
        "                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n",
        "    # draw a number of images for each location\n",
        "    for i, cat in enumerate(categories):\n",
        "        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n",
        "        for j in range(0,figure_cols):\n",
        "            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n",
        "            #print(file)\n",
        "            im=cv2.imread(file)\n",
        "            #print(im)\n",
        "            #print(im.shape)\n",
        "            ax[i, j].imshow(im, resample=True, cmap='gray')\n",
        "            ax[i, j].set_title(cat, fontsize=16)  \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0bifBiHqKln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# below is not needed. This is a high cost operation. This cell was used when the dataset was stored in GCD\n",
        "#import glob\n",
        "#train_files = glob.glob('/content/Histopathologic-Cancer-Detection/train/*')\n",
        "#print(len(train_files))\n",
        "#df_train_files = pd.DataFrame(train_files)\n",
        "#df_train_files.columns = ['filename']\n",
        "#df_train_files['tmp_col'] = 0\n",
        "#df_data_new = df_data.loc[df['id'].isin(df_train_files)]\n",
        "#df_train_files_tmp = df_train_files['filename'].split(\".\")\n",
        "#df_train_files_tmp = pd.DataFrame(df_train_files['filename'].apply(lambda x: x.split('.',1)))\n",
        "#df_train_files_tmp1 = [x[0] for x in df_train_files_tmp.filename[:]]\n",
        "#print(type(df_train_files_tmp1))\n",
        "\n",
        "#df_train_files_tmp2 = pd.DataFrame(df_train_files_tmp1) #.apply(lambda x: x.split('/',1))\n",
        "#df_train_files_tmp2.columns = ['filename']\n",
        "\n",
        "#type(df_train_files_tmp2)\n",
        "#df_train_files_tmp3 = pd.DataFrame(df_train_files_tmp2['filename'].apply(lambda x: x.split('/',-1)))\n",
        "#df_train_files_tmp4 = [x[-1] for x in df_train_files_tmp3.filename[:]]\n",
        "#df_train_files_tmp4[:10]\n",
        "#df_data_new = df_data.loc[df_data['id'].isin(df_train_files_tmp4)]\n",
        "#df_data_new.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxupH8hnGO_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_data.shape)\n",
        "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "print(df_data.columns)\n",
        "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "print(df_data.head())\n",
        "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "print(df_data.id[:10])\n",
        "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGBHalAdoCdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = '/content/Histopathologic-Cancer-Detection/train/' \n",
        "\n",
        "draw_category_images('label',3, df_data, IMAGE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8hDe9nr6-BY",
        "colab_type": "code",
        "outputId": "7f75dbf1-73ad-462c-efc5-93e7ac4214bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# take a random sample of class 0 with size equal to num samples in class 1\n",
        "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
        "# filter out class 1\n",
        "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
        "\n",
        "# concat the dataframes\n",
        "df_data_new = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
        "# shuffle\n",
        "df_data_new = shuffle(df_data_new)\n",
        "\n",
        "df_data_new['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    80000\n",
              "0    80000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "GYfLQRuCVqU4",
        "colab_type": "code",
        "outputId": "3a4a2e87-2dfb-43bf-c9c2-c82390fad963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_data_new['label']\n",
        "\n",
        "df_train, df_val = train_test_split(df_data_new, test_size=0.10, random_state=101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(144000, 2)\n",
            "(16000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AVFwHQv6Vz_M",
        "colab_type": "code",
        "outputId": "2d575617-125c-4282-f984-d3b119cad830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    72000\n",
              "0    72000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "uABPJFW4V5YX",
        "colab_type": "code",
        "outputId": "df777bc0-cbc7-4f18-fb9c-bc086d87518f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df_val['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    8000\n",
              "0    8000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "tYXXqRre_wpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir = '/content/Histopathologic-Cancer-Detection/base_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWCUMICRWchm",
        "colab_type": "code",
        "outputId": "31f37eb6-634d-4761-a127-5dd9bc46c5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a new directory\n",
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/base_dir'):\n",
        "  base_dir = '/content/Histopathologic-Cancer-Detection/base_dir'\n",
        "  os.mkdir(base_dir)\n",
        "else:\n",
        "  print('dir already exists')\n",
        "  data_populated = True\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dir already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IhBFYTuDV6-g",
        "colab_type": "code",
        "outputId": "34153777-da68-46f6-9371-aa5e8753e716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# train_dir\n",
        "    # a_no_tumor_tissue\n",
        "    # b_has_tumor_tissue\n",
        "\n",
        "# val_dir\n",
        "    # a_no_tumor_tissue\n",
        "    # b_has_tumor_tissue\n",
        "\n",
        "if not data_populated:\n",
        "  # create a path to 'base_dir' to which we will join the names of the new folders\n",
        "  # train_dir\n",
        "  train_dir = os.path.join(base_dir, 'train_dir')\n",
        "  os.mkdir(train_dir)\n",
        "\n",
        "  # val_dir\n",
        "  val_dir = os.path.join(base_dir, 'val_dir')\n",
        "  os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "\n",
        "  # [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "  # Inside each folder we create seperate folders for each class\n",
        "\n",
        "  # create new folders inside train_dir\n",
        "  no_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\n",
        "  os.mkdir(no_tumor_tissue)\n",
        "  has_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\n",
        "  os.mkdir(has_tumor_tissue)\n",
        "\n",
        "\n",
        "  # create new folders inside val_dir\n",
        "  no_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\n",
        "  os.mkdir(no_tumor_tissue)\n",
        "  has_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\n",
        "  os.mkdir(has_tumor_tissue)\n",
        "else:\n",
        "  print('sub directories already created')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sub directories already created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "thPPqJ4KWsyb",
        "colab_type": "code",
        "outputId": "f644758b-c9ef-4a68-ff58-9724fccde5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# check that the folders have been created\n",
        "print(os.listdir(base_dir + '/train_dir'))\n",
        "print(os.listdir(base_dir + '/val_dir'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a_no_tumor_tissue', 'b_has_tumor_tissue']\n",
            "['a_no_tumor_tissue', 'b_has_tumor_tissue']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qn5p2k_raF8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the id as the index in df_data\n",
        "df_data_new.set_index('id', inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UjULcyeBaVxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not data_populated:\n",
        "\n",
        "  # Get a list of train and val images\n",
        "  train_list = list(df_train['id'])\n",
        "  val_list = list(df_val['id'])\n",
        "\n",
        "  train_src_dir = '/content/Histopathologic-Cancer-Detection/train'\n",
        "\n",
        "\n",
        "\n",
        "  # Transfer the train images\n",
        "\n",
        "  for image in train_list:\n",
        "\n",
        "      # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "      fname = image + '.tif'\n",
        "      # get the label for a certain image\n",
        "      target = df_data_new.loc[image,'label']\n",
        "\n",
        "      # these must match the folder names\n",
        "      if target == 0:\n",
        "          label = 'a_no_tumor_tissue'\n",
        "      if target == 1:\n",
        "          label = 'b_has_tumor_tissue'\n",
        "\n",
        "      # source path to image\n",
        "      src = os.path.join(train_src_dir, fname)\n",
        "      # destination path to image\n",
        "      dst = os.path.join(train_dir, label, fname)\n",
        "      # copy the image from the source to the destination\n",
        "      shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "  # Transfer the val images\n",
        "\n",
        "  for image in val_list:\n",
        "\n",
        "      # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "      fname = image + '.tif'\n",
        "      # get the label for a certain image\n",
        "      target = df_data_new.loc[image,'label']\n",
        "\n",
        "      # these must match the folder names\n",
        "      if target == 0:\n",
        "          label = 'a_no_tumor_tissue'\n",
        "      if target == 1:\n",
        "          label = 'b_has_tumor_tissue'\n",
        "\n",
        "\n",
        "      # source path to image\n",
        "      src = os.path.join(train_src_dir, fname)\n",
        "      # destination path to image\n",
        "      dst = os.path.join(val_dir, label, fname)\n",
        "      # copy the image from the source to the destination\n",
        "      shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_C7zYgkb11-",
        "colab_type": "code",
        "outputId": "6f83a697-dc5e-42f7-9327-7dd4d903c5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(os.path.join(base_dir, 'train_dir','a_no_tumor_tissue'))))\n",
        "print(len(os.listdir(os.path.join(base_dir, 'train_dir','b_has_tumor_tissue'))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72000\n",
            "72000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v4ZkoZ8H_Tib",
        "colab_type": "code",
        "outputId": "633f8af5-f6b4-4b6c-d033-8a1fc2be52e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(os.path.join(base_dir, 'val_dir','a_no_tumor_tissue'))))\n",
        "print(len(os.listdir(os.path.join(base_dir, 'val_dir','b_has_tumor_tissue'))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwPoEeSUAaDo",
        "colab_type": "code",
        "outputId": "43ff204f-3f1d-4b7d-f310-b3e2f30c99e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_path = base_dir + '/train_dir'\n",
        "valid_path = base_dir + '/val_dir'\n",
        "test_path = '/content/Histopathologic-Cancer-Detection/test'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
        "\n",
        "print(num_train_samples)\n",
        "print(num_val_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144000\n",
            "16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5GOvqm_1_SS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrE6zgoeBAmn",
        "colab_type": "code",
        "outputId": "92f699df-d5bf-4c2c-98e4-8a11b151503a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 144000 images belonging to 2 classes.\n",
            "Found 16000 images belonging to 2 classes.\n",
            "Found 16000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ibYt8xuyBPWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size)) \n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJjiHWcYB8RW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8mnvhfCGOA3",
        "colab_type": "code",
        "outputId": "37db16cf-7c7a-49fd-bef1-0acd053d4d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(val_gen.class_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a_no_tumor_tissue': 0, 'b_has_tumor_tissue': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zAelgNqtGQAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=20, verbose=1,\n",
        "                   callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1efdF4A2Mq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "teTTTnip-Czw",
        "colab_type": "code",
        "outputId": "15bdc850-281a-4c4c-8c57-ef5fc7b1c895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# get the metric names so we can use evaulate_generator\n",
        "model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "3tNcedqk-iU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here the best epoch will be used.\n",
        "\n",
        "!cp 'model.h5' '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection'\n",
        "model.load_weights('/content/Histopathologic-Cancer-Detection/model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTrAViynpg78",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "val_loss, val_acc = \\\n",
        "model.evaluate_generator(test_gen, \n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_acc:', val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPfMNKyNplRC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display the loss and accuracy curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Di-9FCAJqiPw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make a prediction on the val set\n",
        "We need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score."
      ]
    },
    {
      "metadata": {
        "id": "WK6qeRWCqYqu",
        "colab_type": "code",
        "outputId": "91c6f617-4289-487c-cc3d-0081f24a5e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 66s 4ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6n0R3fnHqfsc",
        "colab_type": "code",
        "outputId": "59aaa983-bca1-4ce8-adf6-82765c0353e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "lLWw7gzsqrrL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A note on Keras class index values\n",
        "Keras assigns it's own index value (here 0 and 1) to the classes. It infers the classes based on the folder structure.\n",
        "Important: These index values may not match the index values we were given in the train_labels.csv file.\n",
        "\n",
        "I've used 'a' and 'b' folder name pre-fixes to get keras to assign index values to match what was in the train_labels.csv file - I guessed that keras is assigning the index value based on folder name alphabetical order."
      ]
    },
    {
      "metadata": {
        "id": "_XbipTCuql7n",
        "colab_type": "code",
        "outputId": "53b5adb2-e5c9-49fd-d201-0acb954627ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# This is how to check what index keras has internally assigned to each class. \n",
        "test_gen.class_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a_no_tumor_tissue': 0, 'b_has_tumor_tissue': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "s4XSDggCqxKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Put the predictions into a dataframe.\n",
        "# The columns need to be oredered to match the output of the previous cell\n",
        "\n",
        "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
        "\n",
        "df_preds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUwN8J1qq3L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the true labels\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# Get the predicted labels as probabilities\n",
        "y_pred = df_preds['has_tumor_tissue']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDu46r42q6cs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What is the AUC Score?\n"
      ]
    },
    {
      "metadata": {
        "id": "JATLCr_Dq7We",
        "colab_type": "code",
        "outputId": "c7c6738f-eaab-4930-ff8e-ff33abac319b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.985324734375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "i3XsdHzGrCZj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a Confusion Matrix\n"
      ]
    },
    {
      "metadata": {
        "id": "yFqRGBnoq-lr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Source: Scikit Learn website\n",
        "# http://scikit-learn.org/stable/auto_examples/\n",
        "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
        "# selection-plot-confusion-matrix-py\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hULMGnqrNzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the labels of the test images.\n",
        "\n",
        "test_labels = test_gen.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJKrlsAkrQfK",
        "colab_type": "code",
        "outputId": "c62f9eea-f192-4d96-dcc0-2a39dc4557b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_labels.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "hgQMBaHXrTcW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# argmax returns the index of the max value in a row\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRcMPX7orW1J",
        "colab_type": "code",
        "outputId": "abe31f95-71b2-4d7a-aab1-b1c1c40c22f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Print the label associated with each class\n",
        "test_gen.class_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a_no_tumor_tissue': 0, 'b_has_tumor_tissue': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "RkGWJixhrara",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the labels of the class indices. These need to match the \n",
        "# order shown above.\n",
        "cm_plot_labels = ['no_tumor_tissue', 'has_tumor_tissue']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMF-DeHKrtm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a Classification Report\n"
      ]
    },
    {
      "metadata": {
        "id": "1oKwRZ60rp6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report\n",
        "\n",
        "# For this to work we need y_pred as binary labels not as probabilities\n",
        "y_pred_binary = predictions.argmax(axis=1)\n",
        "\n",
        "report = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n",
        "\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PCoHyBP7r1nK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall = Given a class, will the classifier be able to detect it?\n",
        "Precision = Given a class prediction from a classifier, how likely is it to be correct?\n",
        "F1 Score = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.\n",
        "\n",
        "From the confusion matrix and classification report we see that our model is equally good at detecting both classes."
      ]
    },
    {
      "metadata": {
        "id": "3cq4YaMur5rP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**MAKE A TEST SET PREDICTION**"
      ]
    },
    {
      "metadata": {
        "id": "0_0zZ5RUr3vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Delete base_dir and it's sub folders to free up disk space.\n",
        "\n",
        "#shutil.rmtree('base_dir')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7Gv1e6QsFVQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#[CREATE A TEST FOLDER DIRECTORY STRUCTURE]\n",
        "\n",
        "# We will be feeding test images from a folder into predict_generator().\n",
        "# Keras requires that the path should point to a folder containing images and not\n",
        "# to the images themselves. That is why we are creating a folder (test_images) \n",
        "# inside another folder (test_dir).\n",
        "\n",
        "# test_dir\n",
        "    # test_images\n",
        "\n",
        "# create test_dir\n",
        "test_dir = 'test_dir'\n",
        "os.mkdir(test_dir)\n",
        "    \n",
        "# create test_images inside test_dir\n",
        "test_images = os.path.join(test_dir, 'test_images')\n",
        "os.mkdir(test_images)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tnBRZkTsJgh",
        "colab_type": "code",
        "outputId": "dbdba78e-6d86-443d-a328-8dd108b333f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check that the directory we created exists\n",
        "os.listdir('test_dir')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_images']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "YZ41kJ3dsMAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Transfer the test images into image_dir\n",
        "\n",
        "test_list = os.listdir('/content/Histopathologic-Cancer-Detection/test')\n",
        "\n",
        "for image in test_list:\n",
        "    \n",
        "    fname = image\n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join('/content/Histopathologic-Cancer-Detection/test', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(test_images, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LlSnNmIsQ-W",
        "colab_type": "code",
        "outputId": "b5b91752-6360-4fc2-9285-e4266f9ba459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check that the images are now in the test_images\n",
        "# Should now be 57458 images in the test_images folder\n",
        "\n",
        "len(os.listdir('test_dir/test_images'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "pRvQxDiNsWxJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up the generator**\n"
      ]
    },
    {
      "metadata": {
        "id": "YXx956UCsUiy",
        "colab_type": "code",
        "outputId": "b7c75edf-d8a4-4c7b-f547-6681be561ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_path ='test_dir'\n",
        "\n",
        "\n",
        "# Here we change the path to point to the test_images folder.\n",
        "\n",
        "test_gen = datagen.flow_from_directory(test_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 57458 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wSvabJrZsgio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Make a prediction on the test images**\n"
      ]
    },
    {
      "metadata": {
        "id": "NmlpsrnTsdcH",
        "colab_type": "code",
        "outputId": "c2f01158-e4ea-45b6-d8f9-e80f587aaa0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Make a prediction on the test images\n",
        "num_test_images = 57458\n",
        "\n",
        "# make sure we are using the best epoch\n",
        "model.load_weights('/content/Histopathologic-Cancer-Detection/model.h5')\n",
        "\n",
        "predictions = model.predict_generator(test_gen, steps=num_test_images, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57458/57458 [==============================] - 202s 4ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XYyYuv2Vslun",
        "colab_type": "code",
        "outputId": "514f5393-0091-43ae-95e8-38e65e4aaf84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "# Are the number of predictions correct?\n",
        "# Should be 57458.\n",
        "\n",
        "len(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3a14914ee322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Eu-odmj9A7aY",
        "colab_type": "code",
        "outputId": "e6957086-332a-4d90-b32f-53e5898f32e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "print(predictions[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.5775146e-03 9.9842250e-01]\n",
            " [2.0336887e-02 9.7966307e-01]\n",
            " [8.9127407e-04 9.9910873e-01]\n",
            " [1.0000000e+00 3.4518170e-12]\n",
            " [9.8964953e-01 1.0350401e-02]\n",
            " [4.0871233e-01 5.9128767e-01]\n",
            " [9.8253858e-01 1.7461438e-02]\n",
            " [9.6905351e-01 3.0946460e-02]\n",
            " [1.9593172e-02 9.8040682e-01]\n",
            " [2.4712931e-01 7.5287068e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-EVxttHRspMF",
        "colab_type": "code",
        "outputId": "7fba44f5-813e-492c-d915-1df3f0c36580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Put the predictions into a dataframe\n",
        "\n",
        "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
        "\n",
        "df_preds.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_tumor_tissue</th>\n",
              "      <th>has_tumor_tissue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001578</td>\n",
              "      <td>9.984225e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.020337</td>\n",
              "      <td>9.796631e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000891</td>\n",
              "      <td>9.991087e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.451817e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.989650</td>\n",
              "      <td>1.035040e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   no_tumor_tissue  has_tumor_tissue\n",
              "0         0.001578      9.984225e-01\n",
              "1         0.020337      9.796631e-01\n",
              "2         0.000891      9.991087e-01\n",
              "3         1.000000      3.451817e-12\n",
              "4         0.989650      1.035040e-02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "C3jmNKCdssQl",
        "colab_type": "code",
        "outputId": "5d1c61b7-04b2-4cea-e020-a393f0f22448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# This outputs the file names in the sequence in which \n",
        "# the generator processed the test images.\n",
        "test_filenames = test_gen.filenames\n",
        "\n",
        "# add the filenames to the dataframe\n",
        "df_preds['file_names'] = test_filenames\n",
        "\n",
        "df_preds.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_tumor_tissue</th>\n",
              "      <th>has_tumor_tissue</th>\n",
              "      <th>file_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001578</td>\n",
              "      <td>9.984225e-01</td>\n",
              "      <td>test_images/00006537328c33e284c973d7b39d340809...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.020337</td>\n",
              "      <td>9.796631e-01</td>\n",
              "      <td>test_images/0000ec92553fda4ce39889f9226ace43ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000891</td>\n",
              "      <td>9.991087e-01</td>\n",
              "      <td>test_images/00024a6dee61f12f7856b0fc6be20bc7a4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.451817e-12</td>\n",
              "      <td>test_images/000253dfaa0be9d0d100283b22284ab2f6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.989650</td>\n",
              "      <td>1.035040e-02</td>\n",
              "      <td>test_images/000270442cc15af719583a8172c87cd2bd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   no_tumor_tissue  has_tumor_tissue  \\\n",
              "0         0.001578      9.984225e-01   \n",
              "1         0.020337      9.796631e-01   \n",
              "2         0.000891      9.991087e-01   \n",
              "3         1.000000      3.451817e-12   \n",
              "4         0.989650      1.035040e-02   \n",
              "\n",
              "                                          file_names  \n",
              "0  test_images/00006537328c33e284c973d7b39d340809...  \n",
              "1  test_images/0000ec92553fda4ce39889f9226ace43ca...  \n",
              "2  test_images/00024a6dee61f12f7856b0fc6be20bc7a4...  \n",
              "3  test_images/000253dfaa0be9d0d100283b22284ab2f6...  \n",
              "4  test_images/000270442cc15af719583a8172c87cd2bd...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "CXCiE_B0tN8c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an id column\n",
        "\n",
        "# A file name now has this format: \n",
        "# test_images/00006537328c33e284c973d7b39d340809f7271b.tif\n",
        "\n",
        "# This function will extract the id:\n",
        "# 00006537328c33e284c973d7b39d340809f7271b\n",
        "\n",
        "\n",
        "def extract_id(x):\n",
        "    \n",
        "    # split into a list\n",
        "    a = x.split('/')\n",
        "    # split into a list\n",
        "    b = a[1].split('.')\n",
        "    extracted_id = b[0]\n",
        "    \n",
        "    return extracted_id\n",
        "\n",
        "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
        "\n",
        "df_preds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hplwIwitYNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the predicted labels.\n",
        "# We were asked to predict a probability that the image has tumor tissue\n",
        "y_pred = df_preds['has_tumor_tissue']\n",
        "\n",
        "# get the id column\n",
        "image_id = df_preds['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NWVfMgptf7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create a submission file**\n"
      ]
    },
    {
      "metadata": {
        "id": "2M8Zp0Abtc5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a submission file\n",
        "submission = pd.DataFrame({'id':image_id, \n",
        "                           'label':y_pred, \n",
        "                          }).set_index('id')\n",
        "\n",
        "submission.to_csv('patch_preds.csv', columns=['label']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWFwU2ZbACR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp 'patch_preds.csv' '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9e2t_GjBtln_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kkf4NuyYtqEs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Delete the test_dir directory we created to prevent a Kaggle error.\n",
        "# Kaggle allows a max of 500 files to be saved.\n",
        "\n",
        "shutil.rmtree('test_dir')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8pBonbMwG18g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Below section predicts cancer probability for a given image. The image should be provided in a folder to build batch generator. The pretrained weights will be loaded in a model that is a replica of the model used for training.**"
      ]
    },
    {
      "metadata": {
        "id": "IwpxipQ-NKtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43CIJ4pkLsC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create basic directory structure and get the test images to be used for prediction\n",
        "!mkdir '/content/Histopathologic-Cancer-Detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "356svL-sL1pe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('/content/Histopathologic-Cancer-Detection/test'):\n",
        "  !mkdir '/content/Histopathologic-Cancer-Detection/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHWcod3kL7jG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('/content/Histopathologic-Cancer-Detection/test.zip'):\n",
        "  !cp '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/test.zip' '/content/Histopathologic-Cancer-Detection'\n",
        "else:\n",
        "  print('file exists')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHJY8smfNkyf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "HCDBaseDirTestDir_files = sorted(glob.glob('/content/Histopathologic-Cancer-Detection/test/*'))\n",
        "#archived_files = [f for f in ipynb_files if int(f.split('/')[-1][:2]) % 2]\n",
        "archived_files = [f for f in HCDBaseDirTestDir_files]\n",
        "print(len(archived_files))\n",
        "if len(archived_files) == 0:\n",
        "  !unzip \"/content/Histopathologic-Cancer-Detection/test.zip\" -d \"/content/Histopathologic-Cancer-Detection/test/\"\n",
        "else:\n",
        "  print('already unzipped')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biwsu0KjJ_nr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lB6e9jjWHmbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create replica of the model. No need to compile the model\n",
        "\n",
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model_replica = Sequential()\n",
        "model_replica.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model_replica.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model_replica.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model_replica.add(MaxPooling2D(pool_size = pool_size)) \n",
        "model_replica.add(Dropout(dropout_conv))\n",
        "\n",
        "model_replica.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(MaxPooling2D(pool_size = pool_size))\n",
        "model_replica.add(Dropout(dropout_conv))\n",
        "\n",
        "model_replica.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model_replica.add(MaxPooling2D(pool_size = pool_size))\n",
        "model_replica.add(Dropout(dropout_conv))\n",
        "\n",
        "model_replica.add(Flatten())\n",
        "model_replica.add(Dense(256, activation = \"relu\"))\n",
        "model_replica.add(Dropout(dropout_dense))\n",
        "model_replica.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model_replica.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGRtYaXYJX1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_replica.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKW8cppOIT-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/My Drive/All ML Datasets/Histopathologic-Cancer-Detection/model.h5' '/content/Histopathologic-Cancer-Detection/'\n",
        "model_replica.load_weights('/content/Histopathologic-Cancer-Detection/model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19t2boRbCJ6P",
        "colab_type": "code",
        "outputId": "6b0ac81c-1b1e-48b3-bd7f-74c5babbf897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#find full filename of a random file in the test folder\n",
        "\n",
        "filename = glob.glob('/content/Histopathologic-Cancer-Detection/test/00006537328c33e284c973d7b39d340809*')\n",
        "print(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/Histopathologic-Cancer-Detection/test/00006537328c33e284c973d7b39d340809f7271b.tif']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ms157RIkDc5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/predict'\n",
        "!mkdir '/content/predict/pics'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9Gbvh5oDhiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp '/content/Histopathologic-Cancer-Detection/test/00006537328c33e284c973d7b39d340809f7271b.tif' '/content/predict/pics'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E9NtIcG-JqqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen_pred = ImageDataGenerator(rescale=1.0/255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ancy1JL2DCm4",
        "colab_type": "code",
        "outputId": "585f6ce8-20d1-4971-cdc8-47cd7ec34dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 96\n",
        "test_gen_per_image = datagen_pred.flow_from_directory('/content/predict',\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WD7So_aSDRrh",
        "colab_type": "code",
        "outputId": "f932daa8-742d-40f5-b96a-26a14d5765df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_replica.predict_generator(test_gen_per_image, steps=1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 10ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00157751, 0.9984225 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "Dv7DcUU5EBeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}